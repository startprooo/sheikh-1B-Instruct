name: Model CI/CD

on:
  push:
    branches: [ main ]
    paths:
      - 'model/**'
      - 'app.py'
      - 'quantize.py'
      - 'train_tokenizer.py'
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  REPO_ID: "startprooo/sheikh-1B-instruct"

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch transformers accelerate bitsandbytes sentencepiece protobuf
          pip install gradio huggingface_hub
      
      - name: Test model loading
        run: |
          python -c "
          from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer
          config = LlamaConfig.from_pretrained('./model')
          tokenizer = LlamaTokenizer.from_pretrained('./model')
          print('âœ… Config and tokenizer loaded successfully')
          print(f'Vocab size: {tokenizer.vocab_size}')
          "

  quantize:
    needs: test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        precision: [8, 4]  # INT8 and INT4 quantization
    
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch transformers accelerate bitsandbytes
          pip install huggingface_hub
      
      - name: Run quantization
        run: |
          python quantize.py --bits ${{ matrix.precision }}
      
      - name: Upload to Hugging Face
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python -c "
          from huggingface_hub import HfApi
          api = HfApi()
          
          # Create repo if it doesn't exist
          try:
              api.create_repo(
                  repo_id='${{ env.REPO_ID }}-int${{ matrix.precision }}',
                  private=False,
                  exist_ok=True
              )
          except Exception as e:
              print(f'Repository already exists: {e}')
          
          # Upload model files
          api.upload_folder(
              folder_path='./quantized/sheikh-1B-instruct-int${{ matrix.precision }}',
              repo_id='${{ env.REPO_ID }}-int${{ matrix.precision }}',
              repo_type='model'
          )
          "
